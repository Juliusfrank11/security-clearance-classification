{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n",
      "c:\\Users\\11jul\\Documents\\security-clearance-classification\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['applicant', 'make'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from simplemma import lemmatize\n",
    "\n",
    "\n",
    "def create_lr_model(guideline: str, test_size: float = 0.2):\n",
    "    def preprocess_text(text: str):\n",
    "        gender_neutralizing_dict = {\n",
    "            \"he\": \"applicant\",\n",
    "            \"she\": \"applicant\",\n",
    "            \"husband\": \"spouse\",\n",
    "            \"wife\": \"spouse\",\n",
    "        }\n",
    "        \n",
    "        text_list = text.lower().split()\n",
    "        for i, word in enumerate(text_list):\n",
    "            if word in gender_neutralizing_dict.keys():\n",
    "                text_list[i] = gender_neutralizing_dict[word]\n",
    "\n",
    "        return \" \".join([lemmatize(word, lang=\"en\") for word in text_list if len(word) > 2])\n",
    "\n",
    "    data = pd.read_csv(\n",
    "        f\"C:\\\\Users\\\\11jul\\\\Documents\\\\security-clearance-classification\\\\src\\\\data\\\\formal_finding_results_guideline_{guideline.upper()}.csv\"\n",
    "    )\n",
    "\n",
    "    train_data, test_data = train_test_split(data, test_size=test_size)\n",
    "\n",
    "    model = Pipeline(\n",
    "        [\n",
    "            (\n",
    "                \"tfidf\",\n",
    "                TfidfVectorizer(\n",
    "                    ngram_range=(1, 3),\n",
    "                    stop_words=\"english\",\n",
    "                    preprocessor=preprocess_text,\n",
    "                    min_df=0.01,\n",
    "                    max_df=0.9,\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"clf\",\n",
    "                LogisticRegression(\n",
    "                    class_weight=\"balanced\", penalty='l2', solver=\"liblinear\"\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.fit(train_data[\"text\"], train_data[\"label\"])\n",
    "\n",
    "    return model, train_data, test_data\n",
    "\n",
    "lr, train_data, test_data = {}, {}, {}\n",
    "\n",
    "\n",
    "lr['A'], train_data['A'], test_data['A'] = create_lr_model(\"A\")\n",
    "lr['B'], train_data['B'], test_data['B'] = create_lr_model(\"B\")\n",
    "lr['C'], train_data['C'], test_data['C'] = create_lr_model(\"C\")\n",
    "lr['D'], train_data['D'], test_data['D'] = create_lr_model(\"D\")\n",
    "lr['E'], train_data['E'], test_data['E'] = create_lr_model(\"E\")\n",
    "lr['F'], train_data['F'], test_data['F'] = create_lr_model(\"F\")\n",
    "lr['G'], train_data['G'], test_data['G'] = create_lr_model(\"G\")\n",
    "lr['H'], train_data['H'], test_data['H'] = create_lr_model(\"H\")\n",
    "lr['H'], train_data['H'], test_data['H'] = create_lr_model(\"I\")\n",
    "lr['I'], train_data['I'], test_data['I'] = create_lr_model(\"J\")\n",
    "lr['J'], train_data['J'], test_data['J'] = create_lr_model(\"J\")\n",
    "lr['K'], train_data['K'], test_data['K'] = create_lr_model(\"K\")\n",
    "lr['M'], train_data['M'], test_data['M'] = create_lr_model(\"M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for guideline, model in lr.items():\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": lr[guideline][\"tfidf\"].get_feature_names_out(),\n",
    "            \"coef\": lr[guideline][\"clf\"].coef_[0],\n",
    "        },\n",
    "    ).set_index(\"feature\").sort_values(\"coef\").to_csv(f\"{guideline}_lr_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.66      0.62        32\n",
      "        True       0.69      0.62      0.65        39\n",
      "\n",
      "    accuracy                           0.63        71\n",
      "   macro avg       0.63      0.64      0.63        71\n",
      "weighted avg       0.64      0.63      0.63        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_data_B[\"label\"], lr_B.predict(test_data_B[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_B.predict_proba([\"The applicant has contracts in russia\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife and has a russian wife and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife and has a russian wife and has a russian wife and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife and has a russian wife and has a russian wife and has a russian wife and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen and has a russian wife and has a russian wife and has a russian wife and has a russian wife and has a russian wife and has a russian wife\",\n",
    "                    \"The applicant has contracts in russia and is a russian citizen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
